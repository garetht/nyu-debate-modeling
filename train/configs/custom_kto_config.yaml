Test:
    model_name: stub_model
    target: debater
    llm_type: stub_llm
    training_hyperparameters:
        num_train_epochs: 2
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 8
        optim: paged_adamw_32bit
        learning_rate: 2e-6
        max_grad_norm: 0.3
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
    logging_and_saving_config:
        logging_steps: 1
        output_dir: /fake/file/path
    dataset:
        dataset_type: correctness_judge_preferences
        full_dataset_file_path: 2024-04-23_21:44:04.174661 #2024-03-11_00:19:01.230232
Mixtral:
    model_name: /vast/spa9663/models/trained_models/mixtral-8x7b-bco-505-1/checkpoint-250
    target: debater
    llm_type: mistral
    training_hyperparameters:
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 8
        optim: paged_adamw_32bit
        learning_rate: 5e-6
        max_grad_norm: 0.3
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
    logging_and_saving_config:
        logging_steps: 1
        output_dir: /vast/spa9663/models/trained_models/mixtral-8x7b-bco-507-1
    dataset:
        dataset_type: correctness_judge_preferences
        full_dataset_file_path: 
            - 2024-04-23_21:44:04.174661
            - 2024-05-06_13:03:59.656076