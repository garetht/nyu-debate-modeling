Train - 13B - Alpaca:
    model_name: /vast/spa9663/models/trained_models/Llama-2-13B-32K-Merged-Full-4
    target: debater
    opening_speeches_only: False
    training_hyperparameters:
        num_train_epochs: 4
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: paged_adamw_32bit
        learning_rate: 2e-4
        max_grad_norm: 0.3
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        steps: 100
    logging_and_saving_config:
        logging_steps: 1
        output_dir: /vast/spa9663/models/trained_models/Llama-2-13B-32K-PPO/
        merge_output_dir: /vast/spa9663/models/trained_models/Llama-2-13B-32K-Merged-PPO-Merged/
    prompt_config:
        prompts_file_path: /home/spa9663/debate/prompts/config/prompts.yaml
        prompt_name: Base Prompt
    dataset:
        dataset_type: quality
        train_file_path: /home/spa9663/debate-data/quality/QuALITY.v1.0.1.htmlstripped.train
        val_file_path: /home/spa9663/debate-data/quality/QuALITY.v1.0.1.htmlstripped.dev
        test_file_path: /home/spa9663/debate-data/quality/QuALITY.v1.0.1.htmlstripped.test
        split_type: train