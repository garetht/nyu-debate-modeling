from itertools import count
from openai import OpenAI
import openai
from dotenv import load_dotenv
import os
import csv
import json
import re
from tqdm import tqdm
from openai import AsyncClient
import asyncio
import pandas as pd
import backoff

def read_jsonl(file_path):
    datasets = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            data = json.loads(line.strip())
            datasets.append(data)
    return datasets

def write_jsonl(data, file_path):
    with open(file_path, 'w', encoding='utf-8') as f:
        for item in data:
            json_line = json.dumps(item, ensure_ascii=False)
            f.write(json_line + '\n')


def searching_match(word, datasets):
    """
    Code that searches through the datasets for matching Lojban words
    """
    for d in datasets:
        for w in d["Lojban"]:
            if str(w) == word:
                exact_matches = d[d['Lojban'] == word]
                return exact_matches
    return None

def reiterate_background(choice_a, choice_b):
    set1 = set(choice_a.split()) 
    set2 = set(choice_b.split())
    unique_words = set1.union(set2)

    fuivla = read_jsonl("fuivla_def.jsonl")
    lujvo = read_jsonl("lujvo_def.jsonl")
    gismu = read_jsonl("gismu_def.jsonl")
    cmavo = read_jsonl("cmavo_def.jsonl")
    rafsi = read_jsonl("rafsi_def.jsonl")
    experimental_gismu = read_jsonl("experimental_gismu_def.jsonl")
    experimental_cmavo = read_jsonl("experimental_cmavo_def.jsonl")
    all_datasets = [pd.DataFrame(fuivla), pd.DataFrame(lujvo), pd.DataFrame(gismu), pd.DataFrame(cmavo), pd.DataFrame(experimental_gismu), pd.DataFrame(experimental_cmavo), pd.DataFrame(rafsi)]
    relevant_definitions = []
    for word in unique_words:
        match = searching_match(word, all_datasets)
        if match is not None:
            matched_dict = match.iloc[0].to_dict()
            relevant_definitions.append(matched_dict)
    return relevant_definitions

def csv_converter(csv_file, jsonl_file):
    with open(csv_file, 'r', encoding='utf-8') as csv_file:
        csv_reader = csv.DictReader(csv_file)

        with open(jsonl_file, 'w', encoding='utf-8') as jsonl_file:
            for row in csv_reader:
                json_line = json.dumps(row, ensure_ascii=False)
                jsonl_file.write(json_line + '\n')

@backoff.on_exception(backoff.expo, (openai.RateLimitError, openai.APITimeoutError), max_tries=5)
async def generate_response_cot(messages, data_json):
    response = await openai_client.chat.completions.create(
    model= "o4-mini-2025-04-16",
    messages = messages,
    response_format= {"type": "json_object"},
    )

    try:
        parsed_response_content = json.loads(response.choices[0].message.content)
        print("parsed_response_content: ", parsed_response_content)
    except TypeError as e:
        return False, None, None
    output_value = parsed_response_content.get("answer")
    print("output_value: ", output_value)
    cot_ans = parsed_response_content.get("cot")
    
    if (output_value == data_json["original_key"]) and (output_value == data_json["validator_answer"]):
        return True, output_value, cot_ans
    else:
        return False, output_value, cot_ans

async def check_answer_cot(background_info):
    out_answer = []
    cot_answers = []
    binary_answer = []
    choice_a = ""
    choice_b = ""
    tasks = []
    count = 0
    # Hardcoded path for testing purposes
    # with open(r"C:\Users\tolly\Desktop\MARS\nyu-debate-modeling\task_relevant\converted_data", "r", encoding="utf-8") as f:
    dir_path = os.path.dirname(os.path.realpath(__file__))
    with open(os.path.join(dir_path, "converted_data"), "r", encoding="utf-8") as f:
        for line in tqdm(f, desc="Processing"):
            data_json = json.loads(line.strip())

            choice_a = data_json.get("choice_a")
            choice_b = data_json.get("choice_b")
            sentence = data_json.get("sentence")
            original_explanation = data_json.get("original_explanation")
            validator_answer = data_json.get("validator_answer")
            


            deb_system = """
            You are a Lojban language expert tasked with debating the correctness of translations from English to Lojban.
            - You are concise and clearly state your arguments.
            - Every statement you make is supported by evidence and logical reasoning
            - You must debate in Lojban, using standard Lojban grammar and vocabulary.
            - You must use the definitions provided in the background text to support your arguments.
            - Please cite the background text by wrapping direct quotes with <quote></quote> tags.
            """

            prompt = f"""
            
            Consider the English sentence "{sentence}" 
            Which of the following is a better translation of this sentence into standard Lojban? 
            {choice_a}  
            {choice_b} 
            Exactly one of the answers above is correct. Please provide your response in JSON format, including an 'answer' (A or B) field for the final result and a 'cot' (chain of thought) field explaining your reasoning.

            Example JSON format:
            {{
                "answer": "Your final answer here",
                "cot": "Your step-by-step reasoning process here."
            }}
            """

            prompt_1 = f"""            

Here is the background text that you will be referring to:
{background_info}

The following definitions pulled from the above background may be particularly useful:
{reiterate_background(choice_a, choice_b)}

Here is the task you need to complete:
Consider the English sentence "{sentence}" 
Which of the following is a better translation of this sentence into standard Lojban? 
{choice_a}  
{choice_b} 
Exactly one of the answers above is correct. Please provide your response in JSON format, including an 'answer' (A or B) field for the final result and a 'cot' (chain of thought) field explaining your reasoning.

Example JSON format:
{{
    "answer": "Your final answer here",
    "cot": "Your step-by-step reasoning process here."
}}

Anwer: Let's think step by step
"""
        
            messages=[
                {"role": "system", "content": f"{deb_system}"},
                {"role": "user", "content": f"{prompt_1}"},
            ]
            count += 1
            tasks.append(generate_response_cot(messages, data_json))
            if count % 10 == 0:
                break


    results = await asyncio.gather(*tasks)

    for b_ans, out_ans, cot_ans in results:
        binary_answer.append(b_ans)
        out_answer.append(out_ans)
        cot_answers.append(cot_ans)

    return binary_answer, out_answer, cot_answers


if __name__ == "__main__":

    load_dotenv()
    assert os.getenv("OPENAI_API_KEY") 
    openai_client = AsyncClient()
    csv_converter("data.csv", "converted_data")
    with open("background_test.txt", "r", encoding="utf-8") as f:
        background_content = f.read()

    final_binary, final_out, final_cot = asyncio.run(check_answer_cot(background_content))

    df = pd.DataFrame({
        "Binary Answers": final_binary,
        "Final Answers": final_out,
        "CoT Answers": final_cot
    })

    for val, indx in zip((df[df["Binary Answers"] == False]["CoT Answers"].to_list()), (df.index[df["Binary Answers"] == False].to_list())):
        print(f"\nCoT Answer for jbo_{indx + 1}:")
        print(val)

    print("Final Binary: ", final_binary)

    print("Final Outputs: ", final_out)

    print(sum(final_binary) / len(final_binary))

    print(len(final_binary))

