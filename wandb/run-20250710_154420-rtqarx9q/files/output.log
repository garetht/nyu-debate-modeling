  0%|                                                                                                                                  | 0/2 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
/lambda/nfs/mars-arnesen-gh/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-07-10 15:44:27,124 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6934884786605835	DPO Loss: 0.6931471824645996	SFT Loss: 0.7613959908485413
Could not estimate the number of tokens of the input, floating-point operations will not be computed
2025-07-10 15:44:30,846 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6921354532241821	DPO Loss: 0.6931471824645996	SFT Loss: 0.4907928705215454
2025-07-10 15:44:34,057 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6926807165145874	DPO Loss: 0.6931471824645996	SFT Loss: 0.5998541116714478
2025-07-10 15:44:41,949 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6936915516853333	DPO Loss: 0.6931471824645996	SFT Loss: 0.8020105361938477
2025-07-10 15:44:45,446 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6926202774047852	DPO Loss: 0.6931471824645996	SFT Loss: 0.5877575278282166
2025-07-10 15:44:48,107 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6933231949806213	DPO Loss: 0.6931471824645996	SFT Loss: 0.7283403277397156
2025-07-10 15:44:52,516 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6924216747283936	DPO Loss: 0.6931471824645996	SFT Loss: 0.5480426549911499
2025-07-10 15:44:57,009 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6918709874153137	DPO Loss: 0.6931471824645996	SFT Loss: 0.437907338142395
2025-07-10 15:45:01,094 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6948858499526978	DPO Loss: 0.6931471824645996	SFT Loss: 1.0408772230148315
2025-07-10 15:45:05,159 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6942910552024841	DPO Loss: 0.6931471824645996	SFT Loss: 0.9219138026237488
 50%|█████████████████████████████████████████████████████████████                                                             | 1/2 [00:46<00:46, 46.53s/it]2025-07-10 15:45:08,455 - utils.logger_utils - WARNING - {'loss': 0.6931, 'grad_norm': 0.0007245134329423308, 'learning_rate': 0.0001, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -0.7480772137641907, 'logps/chosen': -0.6918891668319702, 'logits/rejected': -1.0737993717193604, 'logits/chosen': -1.0697765350341797, 'epoch': 0.5}
 50%|█████████████████████████████████████████████████████████████                                                             | 1/2 [00:46<00:46, 46.53s/it]2025-07-10 15:45:09,547 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6936213970184326	DPO Loss: 0.6931471824645996	SFT Loss: 0.7879838347434998
{'loss': 0.6931, 'grad_norm': 0.0007245134329423308, 'learning_rate': 0.0001, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -0.7480772137641907, 'logps/chosen': -0.6918891668319702, 'logits/rejected': -1.0737993717193604, 'logits/chosen': -1.0697765350341797, 'epoch': 0.5}
2025-07-10 15:45:12,665 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.692564845085144	DPO Loss: 0.6931442022323608	SFT Loss: 0.5772762894630432
2025-07-10 15:45:16,379 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.692787766456604	DPO Loss: 0.6944479942321777	SFT Loss: 0.3624005615711212
2025-07-10 15:45:19,213 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.692463755607605	DPO Loss: 0.6931474208831787	SFT Loss: 0.5564051866531372
2025-07-10 15:45:21,854 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6941144466400146	DPO Loss: 0.6931471824645996	SFT Loss: 0.8866005539894104
2025-07-10 15:45:26,163 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6929939985275269	DPO Loss: 0.693144679069519	SFT Loss: 0.6630032658576965
2025-07-10 15:45:30,644 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6935452818870544	DPO Loss: 0.6931459903717041	SFT Loss: 0.773004949092865
2025-07-10 15:45:35,196 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6931393146514893	DPO Loss: 0.6934806704521179	SFT Loss: 0.6252049803733826
2025-07-10 15:45:39,675 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6925029158592224	DPO Loss: 0.6931459903717041	SFT Loss: 0.5645257830619812
2025-07-10 15:45:43,615 - train.impl.smoothed_dpo_trainer - INFO - Overall Loss: 0.6947195529937744	DPO Loss: 0.6931471824645996	SFT Loss: 1.0076171159744263
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:23<00:00, 41.17s/it]2025-07-10 15:45:45,866 - utils.logger_utils - WARNING - {'loss': 0.6932, 'grad_norm': 0.005367744714021683, 'learning_rate': 0.0001, 'rewards/chosen': 0.0013087257975712419, 'rewards/rejected': 0.0014119952684268355, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': -0.00010326951451133937, 'logps/rejected': -0.6766804456710815, 'logps/chosen': -0.6804022192955017, 'logits/rejected': -1.083261251449585, 'logits/chosen': -1.0874500274658203, 'epoch': 1.0}
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:23<00:00, 41.17s/it]2025-07-10 15:45:48,501 - utils.logger_utils - WARNING - {'train_runtime': 88.2831, 'train_samples_per_second': 0.227, 'train_steps_per_second': 0.023, 'train_loss': 0.6931931376457214, 'epoch': 1.0}
{'loss': 0.6932, 'grad_norm': 0.005367744714021683, 'learning_rate': 0.0001, 'rewards/chosen': 0.0013087257975712419, 'rewards/rejected': 0.0014119952684268355, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': -0.00010326951451133937, 'logps/rejected': -0.6766804456710815, 'logps/chosen': -0.6804022192955017, 'logits/rejected': -1.083261251449585, 'logits/chosen': -1.0874500274658203, 'epoch': 1.0}
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:26<00:00, 43.29s/it]
{'train_runtime': 88.2831, 'train_samples_per_second': 0.227, 'train_steps_per_second': 0.023, 'train_loss': 0.6931931376457214, 'epoch': 1.0}
