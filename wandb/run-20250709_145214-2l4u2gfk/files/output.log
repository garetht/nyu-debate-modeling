  0%|                                                                                                                                | 0/222 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
  5%|█████▎                                                                                                                 | 10/222 [01:31<26:29,  7.50s/it]2025-07-09 14:53:59,595 - utils.logger_utils - WARNING - {'loss': 1.48, 'grad_norm': 0.1318359375, 'learning_rate': 0.0002, 'epoch': 0.09009009009009009}
  9%|██████████▋                                                                                                            | 20/222 [03:11<38:38, 11.48s/it]2025-07-09 14:55:40,226 - utils.logger_utils - WARNING - {'loss': 1.3896, 'grad_norm': 0.28125, 'learning_rate': 0.0002, 'epoch': 0.18018018018018017}
{'loss': 1.48, 'grad_norm': 0.1318359375, 'learning_rate': 0.0002, 'epoch': 0.09}
 14%|████████████████                                                                                                       | 30/222 [04:39<28:26,  8.89s/it]2025-07-09 14:57:08,325 - utils.logger_utils - WARNING - {'loss': 1.347, 'grad_norm': 0.2890625, 'learning_rate': 0.0002, 'epoch': 0.2702702702702703}
{'loss': 1.3896, 'grad_norm': 0.28125, 'learning_rate': 0.0002, 'epoch': 0.18}
 18%|█████████████████████▍                                                                                                 | 40/222 [06:29<32:49, 10.82s/it]2025-07-09 14:58:58,255 - utils.logger_utils - WARNING - {'loss': 1.4145, 'grad_norm': 0.2333984375, 'learning_rate': 0.0002, 'epoch': 0.36036036036036034}
{'loss': 1.347, 'grad_norm': 0.2890625, 'learning_rate': 0.0002, 'epoch': 0.27}
 23%|██████████████████████████▊                                                                                            | 50/222 [08:03<27:34,  9.62s/it]2025-07-09 15:00:31,870 - utils.logger_utils - WARNING - {'loss': 1.339, 'grad_norm': 0.23828125, 'learning_rate': 0.0002, 'epoch': 0.45045045045045046}
{'loss': 1.4145, 'grad_norm': 0.2333984375, 'learning_rate': 0.0002, 'epoch': 0.36}
 27%|████████████████████████████████▏                                                                                      | 60/222 [09:39<27:35, 10.22s/it]2025-07-09 15:02:08,114 - utils.logger_utils - WARNING - {'loss': 1.3226, 'grad_norm': 0.2734375, 'learning_rate': 0.0002, 'epoch': 0.5405405405405406}
{'loss': 1.339, 'grad_norm': 0.23828125, 'learning_rate': 0.0002, 'epoch': 0.45}
 32%|█████████████████████████████████████▌                                                                                 | 70/222 [11:18<27:23, 10.81s/it]2025-07-09 15:03:46,541 - utils.logger_utils - WARNING - {'loss': 1.3783, 'grad_norm': 0.2421875, 'learning_rate': 0.0002, 'epoch': 0.6306306306306306}
{'loss': 1.3226, 'grad_norm': 0.2734375, 'learning_rate': 0.0002, 'epoch': 0.54}
 36%|██████████████████████████████████████████▉                                                                            | 80/222 [12:48<22:21,  9.45s/it]2025-07-09 15:05:16,569 - utils.logger_utils - WARNING - {'loss': 1.3732, 'grad_norm': 0.2041015625, 'learning_rate': 0.0002, 'epoch': 0.7207207207207207}
{'loss': 1.3783, 'grad_norm': 0.2421875, 'learning_rate': 0.0002, 'epoch': 0.63}
 41%|████████████████████████████████████████████████▏                                                                      | 90/222 [14:21<22:12, 10.09s/it]2025-07-09 15:06:49,790 - utils.logger_utils - WARNING - {'loss': 1.4181, 'grad_norm': 0.259765625, 'learning_rate': 0.0002, 'epoch': 0.8108108108108109}
{'loss': 1.3732, 'grad_norm': 0.2041015625, 'learning_rate': 0.0002, 'epoch': 0.72}
 45%|█████████████████████████████████████████████████████▏                                                                | 100/222 [15:46<16:04,  7.91s/it]2025-07-09 15:08:15,283 - utils.logger_utils - WARNING - {'loss': 1.258, 'grad_norm': 0.23828125, 'learning_rate': 0.0002, 'epoch': 0.9009009009009009}
{'loss': 1.4181, 'grad_norm': 0.259765625, 'learning_rate': 0.0002, 'epoch': 0.81}
 50%|██████████████████████████████████████████████████████████▍                                                           | 110/222 [17:09<14:54,  7.99s/it]2025-07-09 15:09:37,885 - utils.logger_utils - WARNING - {'loss': 1.319, 'grad_norm': 0.333984375, 'learning_rate': 0.0002, 'epoch': 0.990990990990991}
{'loss': 1.258, 'grad_norm': 0.23828125, 'learning_rate': 0.0002, 'epoch': 0.9}
 54%|███████████████████████████████████████████████████████████████▊                                                      | 120/222 [18:49<16:20,  9.61s/it]2025-07-09 15:11:18,238 - utils.logger_utils - WARNING - {'loss': 1.2748, 'grad_norm': 0.26953125, 'learning_rate': 0.0002, 'epoch': 1.0810810810810811}
{'loss': 1.319, 'grad_norm': 0.333984375, 'learning_rate': 0.0002, 'epoch': 0.99}
 59%|█████████████████████████████████████████████████████████████████████                                                 | 130/222 [20:23<15:44, 10.26s/it]2025-07-09 15:12:52,227 - utils.logger_utils - WARNING - {'loss': 1.204, 'grad_norm': 0.287109375, 'learning_rate': 0.0002, 'epoch': 1.1711711711711712}
{'loss': 1.2748, 'grad_norm': 0.26953125, 'learning_rate': 0.0002, 'epoch': 1.08}
 63%|██████████████████████████████████████████████████████████████████████████▍                                           | 140/222 [22:00<14:46, 10.81s/it]2025-07-09 15:14:28,512 - utils.logger_utils - WARNING - {'loss': 1.293, 'grad_norm': 0.2578125, 'learning_rate': 0.0002, 'epoch': 1.2612612612612613}
{'loss': 1.204, 'grad_norm': 0.287109375, 'learning_rate': 0.0002, 'epoch': 1.17}
 68%|███████████████████████████████████████████████████████████████████████████████▋                                      | 150/222 [23:39<13:20, 11.12s/it]2025-07-09 15:16:07,757 - utils.logger_utils - WARNING - {'loss': 1.308, 'grad_norm': 0.2353515625, 'learning_rate': 0.0002, 'epoch': 1.3513513513513513}
{'loss': 1.293, 'grad_norm': 0.2578125, 'learning_rate': 0.0002, 'epoch': 1.26}
 72%|█████████████████████████████████████████████████████████████████████████████████████                                 | 160/222 [25:13<10:51, 10.51s/it]2025-07-09 15:17:41,791 - utils.logger_utils - WARNING - {'loss': 1.1977, 'grad_norm': 0.2890625, 'learning_rate': 0.0002, 'epoch': 1.4414414414414414}
{'loss': 1.308, 'grad_norm': 0.2353515625, 'learning_rate': 0.0002, 'epoch': 1.35}
 77%|██████████████████████████████████████████████████████████████████████████████████████████▎                           | 170/222 [26:28<05:56,  6.86s/it]2025-07-09 15:18:56,740 - utils.logger_utils - WARNING - {'loss': 1.2444, 'grad_norm': 0.208984375, 'learning_rate': 0.0002, 'epoch': 1.5315315315315314}
{'loss': 1.1977, 'grad_norm': 0.2890625, 'learning_rate': 0.0002, 'epoch': 1.44}
 81%|███████████████████████████████████████████████████████████████████████████████████████████████▋                      | 180/222 [28:07<07:23, 10.55s/it]2025-07-09 15:20:35,614 - utils.logger_utils - WARNING - {'loss': 1.3765, 'grad_norm': 0.30078125, 'learning_rate': 0.0002, 'epoch': 1.6216216216216215}
{'loss': 1.2444, 'grad_norm': 0.208984375, 'learning_rate': 0.0002, 'epoch': 1.53}
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████▉                 | 190/222 [29:38<04:49,  9.04s/it]2025-07-09 15:22:07,141 - utils.logger_utils - WARNING - {'loss': 1.2401, 'grad_norm': 0.1943359375, 'learning_rate': 0.0002, 'epoch': 1.7117117117117115}
{'loss': 1.3765, 'grad_norm': 0.30078125, 'learning_rate': 0.0002, 'epoch': 1.62}
 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 200/222 [31:13<03:07,  8.53s/it]2025-07-09 15:23:41,633 - utils.logger_utils - WARNING - {'loss': 1.3412, 'grad_norm': 0.427734375, 'learning_rate': 0.0002, 'epoch': 1.8018018018018018}
{'loss': 1.2401, 'grad_norm': 0.1943359375, 'learning_rate': 0.0002, 'epoch': 1.71}
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌      | 210/222 [32:41<01:44,  8.69s/it]2025-07-09 15:25:10,073 - utils.logger_utils - WARNING - {'loss': 1.3147, 'grad_norm': 0.287109375, 'learning_rate': 0.0002, 'epoch': 1.8918918918918919}
{'loss': 1.3412, 'grad_norm': 0.427734375, 'learning_rate': 0.0002, 'epoch': 1.8}
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 220/222 [34:15<00:18,  9.19s/it]2025-07-09 15:26:43,590 - utils.logger_utils - WARNING - {'loss': 1.2737, 'grad_norm': 0.2890625, 'learning_rate': 0.0002, 'epoch': 1.981981981981982}
{'loss': 1.3147, 'grad_norm': 0.287109375, 'learning_rate': 0.0002, 'epoch': 1.89}
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 222/222 [34:28<00:00,  7.90s/it]2025-07-09 15:26:57,326 - utils.logger_utils - WARNING - {'train_runtime': 2092.7845, 'train_samples_per_second': 1.697, 'train_steps_per_second': 0.106, 'train_loss': 1.3210693662231032, 'epoch': 2.0}
{'loss': 1.2737, 'grad_norm': 0.2890625, 'learning_rate': 0.0002, 'epoch': 1.98}
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 222/222 [34:28<00:00,  9.32s/it]
{'train_runtime': 2092.7845, 'train_samples_per_second': 1.697, 'train_steps_per_second': 0.106, 'train_loss': 1.3210693662231032, 'epoch': 2.0}
Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.22it/s]
