  0%|                                                                                                                                | 0/222 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
  5%|█████▎                                                                                                                 | 10/222 [02:10<44:30, 12.60s/it]2025-07-11 14:41:27,895 - utils.logger_utils - WARNING - {'loss': 1.3508, 'grad_norm': 0.1650390625, 'learning_rate': 0.0002, 'epoch': 0.09009009009009009}
  9%|██████████▋                                                                                                            | 20/222 [04:24<45:59, 13.66s/it]2025-07-11 14:43:41,856 - utils.logger_utils - WARNING - {'loss': 1.4857, 'grad_norm': 0.318359375, 'learning_rate': 0.0002, 'epoch': 0.18018018018018017}
{'loss': 1.3508, 'grad_norm': 0.1650390625, 'learning_rate': 0.0002, 'epoch': 0.09}
 14%|████████████████                                                                                                       | 30/222 [06:27<37:21, 11.68s/it]2025-07-11 14:45:45,122 - utils.logger_utils - WARNING - {'loss': 1.3224, 'grad_norm': 0.23828125, 'learning_rate': 0.0002, 'epoch': 0.2702702702702703}
{'loss': 1.4857, 'grad_norm': 0.318359375, 'learning_rate': 0.0002, 'epoch': 0.18}
 18%|█████████████████████▍                                                                                                 | 40/222 [08:40<38:53, 12.82s/it]2025-07-11 14:47:58,331 - utils.logger_utils - WARNING - {'loss': 1.3481, 'grad_norm': 0.23046875, 'learning_rate': 0.0002, 'epoch': 0.36036036036036034}
{'loss': 1.3224, 'grad_norm': 0.23828125, 'learning_rate': 0.0002, 'epoch': 0.27}
 23%|██████████████████████████▊                                                                                            | 50/222 [10:53<42:31, 14.83s/it]2025-07-11 14:50:11,339 - utils.logger_utils - WARNING - {'loss': 1.2623, 'grad_norm': 0.234375, 'learning_rate': 0.0002, 'epoch': 0.45045045045045046}
{'loss': 1.3481, 'grad_norm': 0.23046875, 'learning_rate': 0.0002, 'epoch': 0.36}
 27%|████████████████████████████████▏                                                                                      | 60/222 [13:09<36:49, 13.64s/it]2025-07-11 14:52:26,730 - utils.logger_utils - WARNING - {'loss': 1.235, 'grad_norm': 0.2216796875, 'learning_rate': 0.0002, 'epoch': 0.5405405405405406}
{'loss': 1.2623, 'grad_norm': 0.234375, 'learning_rate': 0.0002, 'epoch': 0.45}
 32%|█████████████████████████████████████▌                                                                                 | 70/222 [15:22<35:39, 14.08s/it]2025-07-11 14:54:39,879 - utils.logger_utils - WARNING - {'loss': 1.1694, 'grad_norm': 0.29296875, 'learning_rate': 0.0002, 'epoch': 0.6306306306306306}
{'loss': 1.235, 'grad_norm': 0.2216796875, 'learning_rate': 0.0002, 'epoch': 0.54}
 36%|██████████████████████████████████████████▉                                                                            | 80/222 [17:40<33:44, 14.26s/it]2025-07-11 14:56:58,340 - utils.logger_utils - WARNING - {'loss': 1.2244, 'grad_norm': 0.2392578125, 'learning_rate': 0.0002, 'epoch': 0.7207207207207207}
{'loss': 1.1694, 'grad_norm': 0.29296875, 'learning_rate': 0.0002, 'epoch': 0.63}
 41%|████████████████████████████████████████████████▏                                                                      | 90/222 [19:53<30:03, 13.66s/it]2025-07-11 14:59:10,832 - utils.logger_utils - WARNING - {'loss': 1.2076, 'grad_norm': 0.236328125, 'learning_rate': 0.0002, 'epoch': 0.8108108108108109}
{'loss': 1.2244, 'grad_norm': 0.2392578125, 'learning_rate': 0.0002, 'epoch': 0.72}
 45%|█████████████████████████████████████████████████████▏                                                                | 100/222 [22:01<26:39, 13.11s/it]2025-07-11 15:01:18,890 - utils.logger_utils - WARNING - {'loss': 1.1838, 'grad_norm': 0.259765625, 'learning_rate': 0.0002, 'epoch': 0.9009009009009009}
{'loss': 1.2076, 'grad_norm': 0.236328125, 'learning_rate': 0.0002, 'epoch': 0.81}
 50%|██████████████████████████████████████████████████████████▍                                                           | 110/222 [24:10<23:19, 12.49s/it]2025-07-11 15:03:27,900 - utils.logger_utils - WARNING - {'loss': 1.1893, 'grad_norm': 0.28125, 'learning_rate': 0.0002, 'epoch': 0.990990990990991}
{'loss': 1.1838, 'grad_norm': 0.259765625, 'learning_rate': 0.0002, 'epoch': 0.9}
 54%|███████████████████████████████████████████████████████████████▊                                                      | 120/222 [26:21<22:47, 13.40s/it]2025-07-11 15:05:39,232 - utils.logger_utils - WARNING - {'loss': 1.0431, 'grad_norm': 0.2333984375, 'learning_rate': 0.0002, 'epoch': 1.0810810810810811}
{'loss': 1.1893, 'grad_norm': 0.28125, 'learning_rate': 0.0002, 'epoch': 0.99}
 59%|█████████████████████████████████████████████████████████████████████                                                 | 130/222 [28:25<19:34, 12.77s/it]2025-07-11 15:07:43,164 - utils.logger_utils - WARNING - {'loss': 1.1451, 'grad_norm': 0.2255859375, 'learning_rate': 0.0002, 'epoch': 1.1711711711711712}
{'loss': 1.0431, 'grad_norm': 0.2333984375, 'learning_rate': 0.0002, 'epoch': 1.08}
 63%|██████████████████████████████████████████████████████████████████████████▍                                           | 140/222 [30:28<17:16, 12.64s/it]2025-07-11 15:09:45,702 - utils.logger_utils - WARNING - {'loss': 1.1757, 'grad_norm': 0.28515625, 'learning_rate': 0.0002, 'epoch': 1.2612612612612613}
{'loss': 1.1451, 'grad_norm': 0.2255859375, 'learning_rate': 0.0002, 'epoch': 1.17}
 68%|███████████████████████████████████████████████████████████████████████████████▋                                      | 150/222 [32:43<14:43, 12.27s/it]2025-07-11 15:12:01,000 - utils.logger_utils - WARNING - {'loss': 1.1284, 'grad_norm': 0.337890625, 'learning_rate': 0.0002, 'epoch': 1.3513513513513513}
{'loss': 1.1757, 'grad_norm': 0.28515625, 'learning_rate': 0.0002, 'epoch': 1.26}
 72%|█████████████████████████████████████████████████████████████████████████████████████                                 | 160/222 [34:53<13:26, 13.01s/it]2025-07-11 15:14:11,014 - utils.logger_utils - WARNING - {'loss': 1.1218, 'grad_norm': 0.296875, 'learning_rate': 0.0002, 'epoch': 1.4414414414414414}
{'loss': 1.1284, 'grad_norm': 0.337890625, 'learning_rate': 0.0002, 'epoch': 1.35}
 77%|██████████████████████████████████████████████████████████████████████████████████████████▎                           | 170/222 [37:04<11:25, 13.19s/it]2025-07-11 15:16:21,633 - utils.logger_utils - WARNING - {'loss': 1.1326, 'grad_norm': 0.330078125, 'learning_rate': 0.0002, 'epoch': 1.5315315315315314}
{'loss': 1.1218, 'grad_norm': 0.296875, 'learning_rate': 0.0002, 'epoch': 1.44}
 81%|███████████████████████████████████████████████████████████████████████████████████████████████▋                      | 180/222 [39:20<08:57, 12.80s/it]2025-07-11 15:18:37,779 - utils.logger_utils - WARNING - {'loss': 1.1573, 'grad_norm': 0.349609375, 'learning_rate': 0.0002, 'epoch': 1.6216216216216215}
{'loss': 1.1326, 'grad_norm': 0.330078125, 'learning_rate': 0.0002, 'epoch': 1.53}
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████▉                 | 190/222 [41:29<07:06, 13.33s/it]2025-07-11 15:20:46,795 - utils.logger_utils - WARNING - {'loss': 1.135, 'grad_norm': 0.37109375, 'learning_rate': 0.0002, 'epoch': 1.7117117117117115}
{'loss': 1.1573, 'grad_norm': 0.349609375, 'learning_rate': 0.0002, 'epoch': 1.62}
 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 200/222 [43:32<04:21, 11.90s/it]2025-07-11 15:22:49,981 - utils.logger_utils - WARNING - {'loss': 1.1146, 'grad_norm': 0.396484375, 'learning_rate': 0.0002, 'epoch': 1.8018018018018018}
{'loss': 1.135, 'grad_norm': 0.37109375, 'learning_rate': 0.0002, 'epoch': 1.71}
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌      | 210/222 [45:43<02:50, 14.22s/it]2025-07-11 15:25:00,681 - utils.logger_utils - WARNING - {'loss': 1.1843, 'grad_norm': 0.30859375, 'learning_rate': 0.0002, 'epoch': 1.8918918918918919}
{'loss': 1.1146, 'grad_norm': 0.396484375, 'learning_rate': 0.0002, 'epoch': 1.8}
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 220/222 [47:54<00:26, 13.42s/it]2025-07-11 15:27:11,771 - utils.logger_utils - WARNING - {'loss': 1.1248, 'grad_norm': 0.33203125, 'learning_rate': 0.0002, 'epoch': 1.981981981981982}
{'loss': 1.1843, 'grad_norm': 0.30859375, 'learning_rate': 0.0002, 'epoch': 1.89}
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 222/222 [48:21<00:00, 13.51s/it]2025-07-11 15:27:40,797 - utils.logger_utils - WARNING - {'train_runtime': 2904.8492, 'train_samples_per_second': 1.223, 'train_steps_per_second': 0.076, 'train_loss': 1.200749968623256, 'epoch': 2.0}
{'loss': 1.1248, 'grad_norm': 0.33203125, 'learning_rate': 0.0002, 'epoch': 1.98}
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 222/222 [48:23<00:00, 13.08s/it]
{'train_runtime': 2904.8492, 'train_samples_per_second': 1.223, 'train_steps_per_second': 0.076, 'train_loss': 1.200749968623256, 'epoch': 2.0}
Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.29it/s]
