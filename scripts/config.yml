# config.yml
# ──────────────────────────────────────────────────────────────────────────────
# 1. Which model are we fine-tuning?
model_name: gpt-4-turbo
reference_model_name: gpt-4-turbo          # optional, only if you want to distill from another
llm_type: openai                            # keep “llama” if you’re using Llama under the hood

# 2. Prompt loading (same as before)
prompt_config:
#  file_path: prompts.yml
  default_prompt_name: Judge Prompt
#  is_memorized: false

# 3. Which dataset(s) to convert?
dataset:
  - dataset_type: quality_debates # QUALITY_CONSULTANCY
    #full_dataset_file_path: /home/ubuntu/mars-arnesen-gh/leonidtsyplenkov/data/datasets/quality-debates/debates-readable.jsonl
    full_dataset_file_path: /home/ubuntu/mars-arnesen-gh/leonidtsyplenkov/sft_data/converted_khan_only_debate_filled.jsonl
    split_type: train                      # must match the SplitType enum (TRAIN, VALIDATION, TEST)
  # - dataset_type: HUGGING_FACE           # you can list more datasets here if you need

# 4. What are we training? (Judge, not Debater)
target: JUDGE

# 5. Other SFT options
opening_speeches_only: false
requires_token: false
max_length: 1024

# 6. Scratchpad (typically false for judge)
scratchpad_config:
  use_scratchpad: false

# 7. How to format transcripts
speech_structure:
  - default_debate #default_consultancy
