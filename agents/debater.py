from __future__ import annotations

from agents.agent import Agent
from agents.models import Model, HumanModel, OfflineModel
from agents.transcript import SpeechFormat, Transcript
from prompts import Prompt, PromptTag
from utils import LoggerUtils
import utils.constants as constants

from typing import Optional, Union
import copy


class Debater(Agent):
    def __init__(
        self,
        name: str,
        prompt: Prompt | list[Prompt],
        model: Model,
        num_speeches: int,
        speech_format: Optional[SpeechFormat] = None,
        use_scratchpad: bool = False,
        quotes_require_validation: bool = True,
    ):
        """
        An abstraction that corresponds to a debater in the round.

        Params:
            name: A string to identify the debater. It needs only to be unique within its own debate round.
            is_debater: Boolean indicating whether the agent is a debater or a judge.
            prompt: The Prompt structure that controls the inputs to the models. A list is passed in for batch processing.
            model: The model that actually performs the text generation.
            num_speeches: The number of speeches each debater will generate in the round.
            speech_format: The order of speeches that the debater is expecting to receive.
            use_scratchpad: Whether or not the debater has access to a hidden scratchpad before its speeches.
            quotes_require_validation: Whether or not the speeches generated by this agent already have had their quotes
                validated. Quote validation takes some time, so this helps us perform validation only when necessary. This
                is true for speeches generated by the HumanModel and false for the other models.
        """
        super().__init__(
            name=name,
            is_debater=True,
            prompt=prompt,
            model=model,
            num_speeches=num_speeches,
            receive_validated_quotes=False,
            quotes_require_validation=quotes_require_validation,
            speech_format=speech_format
            if speech_format
            else DebaterUtils.get_default_speech_format(name, num_speeches, use_scratchpad),
        )
        self.use_scratchpad = use_scratchpad
        self.logger = LoggerUtils.get_default_logger(__name__)

    def generate(self, max_new_tokens=300, round_idx: int = 0) -> Optional[list[str]]:
        """Generates new text using the pre-existing transcript as input"""
        model_inputs = [transcript.to_model_input() for transcript in self.transcripts]
        return self.model.predict(
            inputs=model_inputs, max_new_tokens=max_new_tokens, debater_name=self.name, round_idx=round_idx
        )

    def copy(self, transcripts: Optional[list[Transcript]] = None) -> Debater:
        """Deepcopies the debater (except for the model, which is a shallow copy)"""
        debater = Debater(
            name=self.name,
            prompt=[copy.deepcopy(prompt) for prompt in self.prompts],
            model=self.model,
            num_speeches=self.num_speeches,
            speech_format=self.speech_format,
            use_scratchpad=self.use_scratchpad,
        )
        if transcripts:
            debater.transcripts = [transcript.copy() for transcript in transcripts]
        return debater

    def __call__(self) -> Optional[list[str]]:
        """Generates new text using the pre-existing transcript as input. If it has access to a
        scratchpad, it will use that but keep those results hidden"""
        if self.use_scratchpad:
            batch_reasoning = self.generate(max_new_tokens=300)
            for i, reasoning in enumerate(batch_reasoning):
                super().receive_message(speaker=self.name, content=reasoning, idx=i)
                self.logger.debug(reasoning)

        return self.generate(max_new_tokens=300)


class BoNDebater(Debater):
    def __init__(self, debater: Debater, n: int, prompts: Optional[list[Prompt]] = None, evaluated: bool = True):
        """
        A debater model that generates multiple versions of the same speech for BoN comparisons.

        Params:
            debater: The underlying debater that is to be converted to a BoNDebater
            n: The number of speeches to generate for each input.
            prompts: The Prompt structure that controls the inputs to the models. A list is passed in for batch processing.
            evaluated: indicates whether the round has already been judged.
        """
        super().__init__(
            name=debater.name,
            prompt=BoNDebater.construct_prompts(debater=debater, n=n if evaluated else 1, prompts=prompts),
            model=debater.model,
            num_speeches=debater.num_speeches,
            speech_format=DebaterUtils.get_bon_speech_format(debater.name, debater.num_speeches, debater.use_scratchpad),
        )
        self.n = n
        self.evaluated = evaluated

    @classmethod
    def construct_prompts(cls, debater: Debater, n: int, prompts: Optional[list[Prompt]]):
        """Copies the prompts from the existing debater"""
        prompts = prompts if prompts else debater.prompts
        return [copy.deepcopy(prompts[i % len(prompts)]) for i in range(n)]

    def copy(self, transcripts: Optional[list[Transcript]] = None) -> Debater:
        """Deepcopies the debater (except for the model, which is a shallow copy)"""
        debater = super().copy(transcripts=self.transcripts)
        return BoNDebater(debater=debater, n=self.n, prompts=self.prompts, evaluated=self.evaluated)

    def generate(self, max_new_tokens=300) -> Optional[list[str]]:
        """Generates new text based on the pre-existing transcripts"""
        prediction = []
        for transcript in self.transcripts:
            prediction.extend(
                self.model.predict(
                    inputs=[transcript.to_model_input()],
                    max_new_tokens=max_new_tokens,
                    debater_name=self.name,
                )
            )
        if not self.evaluated and self.n > len(prediction):
            prediction.extend([copy.deepcopy(prediction[0]) for i in range(self.n - len(prediction))])
        return prediction


class OfflineDebater(Debater):
    def __init__(self, debater: Debater, file_path: str, first_debater_prompt: Prompt, round_idx: int = 0):
        """
        A separate abstraction for a debater that uses an OfflineModel.

        Params:
            debater: The underlying debater that is to be converted to an OfflineDebater
            file_path: The path to the transcripts that the OfflineModel will use to replay text
            first_debater_prompt: The prompt of the first debater in te debate round (needed for parsing)
            round_idx: The index of the round within the context off all the rounds found at the file_path.
        """
        super().__init__(
            name=debater.name,
            prompt=debater.prompts,
            model=OfflineModel(
                alias=debater.model.alias, is_debater=debater.is_debater, file_path=file_path, prompt=first_debater_prompt
            ),
            num_speeches=debater.num_speeches,
            speech_format=debater.speech_format,
            quotes_require_validation=False,
        )
        self.round_idx = round_idx
        self.file_path = file_path
        self.first_debater_prompt = first_debater_prompt

    def copy(self, transcripts: Optional[list[Transcript]] = None) -> Debater:
        """Deepcopies the debater"""
        debater = super().copy(transcripts=self.transcripts)
        return OfflineDebater(
            debater=debater,
            file_path=self.file_path,
            first_debater_prompt=self.first_debater_prompt,
            round_idx=self.round_idx,
        )

    def __call__(self) -> Optional[list[str]]:
        """Generates new text using the OfflineModel"""
        return self.generate(max_new_tokens=300, round_idx=self.round_idx)


class HumanDebater(Debater):
    def __init__(self, debater: Debater, speeches: list[SpeechData]):
        """
        A separate abstraction for a debater that uses a HumanModel.

        Params:
            debater: The undelrying debater that is to be converted to a HumanDebater.
            speeches: The list of speeches from the dataset that are to be delivered when text is generated
        """
        super().__init__(
            name=debater.name,
            prompt=debater.prompts,
            model=HumanModel(
                alias=debater.model.alias, is_debater=debater.is_debater, debater_name=debater.name, speeches=speeches
            ),
            num_speeches=debater.num_speeches,
            speech_format=debater.speech_format,
            quotes_require_validation=False,
        )


class DebaterUtils:
    @classmethod
    def get_speech_format(cls, name: str, num_speeches: int, use_scratchpad: bool, best_of_n: bool = False):
        """Generates the order of speeches that the debater expects to receive"""
        opponent_name = (
            constants.DEFAULT_DEBATER_A_NAME
            if name == constants.DEFAULT_DEBATER_B_NAME
            else constants.DEFAULT_DEBATER_B_NAME
        )
        pre_debate = (
            SpeechFormat(name)
            .add(prompt_tag=PromptTag.OVERALL_SYSTEM)
            .add(prompt_tag=PromptTag.DEBATER_SYSTEM)
            .add(prompt_tag=PromptTag.PRE_DEBATE)
        )

        judge_questions = (
            SpeechFormat(name)
            .add(prompt_tag=PromptTag.PRE_JUDGE_QUESTIONS)
            .add_user_inputted_speech(expected_speaker=constants.DEFAULT_JUDGE_NAME)
        )

        scratchpad = (
            SpeechFormat(name)
            .add(prompt_tag=PromptTag.PREVIOUS_DEBATER_SCRATCHPAD, last_only_prompt_tag=PromptTag.DEBATER_SCRATCHPAD)
            .add_user_inputted_speech(expected_speaker=name)
        )
        own_speech = SpeechFormat(name).add(prompt_tag=PromptTag.PRE_SPEECH).add_user_inputted_speech(expected_speaker=name)
        if use_scratchpad:
            own_speech = scratchpad.add_format(speech_format=own_speech)

        opponent_speech = (
            SpeechFormat(name)
            .add(prompt_tag=PromptTag.PRE_OPPONENT_SPEECH)
            .add_user_inputted_speech(expected_speaker=opponent_name)
        )

        opening_statements = (
            SpeechFormat(name).add(prompt_tag=PromptTag.PRE_OPENING_SPEECH).add_format(speech_format=own_speech)
        )

        if not best_of_n:
            opening_statements = opening_statements.add_format(speech_format=opponent_speech)

        later_arguments = (
            SpeechFormat(name)
            .add_format(speech_format=judge_questions)
            .add_format(speech_format=own_speech if name == constants.DEFAULT_DEBATER_A_NAME else opponent_speech)
            .add_format(speech_format=opponent_speech if name == constants.DEFAULT_DEBATER_A_NAME else own_speech)
        )

        decision = (
            SpeechFormat(name)
            .add(prompt_tag=PromptTag.JUDGE_DECISION_FOR_DEBATER)
            .add_user_inputted_speech(expected_speaker=constants.DEFAULT_JUDGE_NAME)
        )

        return (
            SpeechFormat(name)
            .add_format(speech_format=pre_debate)
            .add_format(speech_format=opening_statements)
            .add_format(speech_format=later_arguments, repeats=(num_speeches - 1))
            .add_format(speech_format=decision)
        )

    @classmethod
    def get_default_speech_format(cls, name: str, num_speeches: int, use_scratchpad: bool):
        """Gets the speech orders for a normal (non-BoN) debater"""
        return DebaterUtils.get_speech_format(
            name=name, num_speeches=num_speeches, use_scratchpad=use_scratchpad, best_of_n=False
        )

    @classmethod
    def get_bon_speech_format(cls, name: str, num_speeches: int, use_scratchpad: bool):
        """Gets the speech order for a BoN debater"""
        return DebaterUtils.get_speech_format(
            name=name, num_speeches=num_speeches, use_scratchpad=use_scratchpad, best_of_n=True
        )
